# 3-Month General Learning Goal (Vocational Alignment)

## Objective
Over the next 3 months, I will build foundational CS and AI capabilities, with an emphasis on LLM systems, so that I can independently design, implement, and evaluate a small-to-medium-scale ML system with clear documentation, reproducibility, and defensible design choices.

The goal is not broad exposure, but **career capital**: producing concrete artifacts that demonstrate systems thinking, probabilistic reasoning, and applied ML competence.

---

## Scope of Learning

### 1. CS & Quantitative Foundations
I will strengthen my ability to reason about uncertainty, randomness, and system behavior by translating theoretical concepts into working code.

**Focus areas:**
- Probability & simulation (Monte Carlo methods, variance, uncertainty)
- Stochastic processes and evaluation noise
- Basic system dynamics and feedback loops

**Deliverables:**
- A documented repository implementing probabilistic simulations
- Clear explanations of assumptions, tradeoffs, and failure modes

---

### 2. Intelligent Systems & Agents
I will apply systems thinking through small intelligent or agent-based environments, emphasizing how decisions are represented, executed, and evaluated in code.

**Focus areas:**
- Agent behavior and control logic
- Environment–agent interaction
- Evaluation and logging of outcomes

**Deliverables:**
- A small intelligent systems or agent project
- Modular code structure with clear interfaces
- Short write-up explaining system design

---

### 3. LLM Systems & Evaluation
I will move beyond prompt-level interaction with LLMs and focus on **measurement, evaluation, and reproducibility**.

**Focus areas:**
- LLM inference pipelines
- Output consistency and robustness
- Basic evaluation metrics and aggregation
- Experiment configuration and logging

**Deliverables:**
- A lightweight LLM evaluation pipeline
- Metrics beyond raw output inspection
- A README explaining evaluation design and limitations

---

## Reproducibility & Engineering Discipline
Across all projects, I will prioritize engineering rigor.

**Standards:**
- Clear configuration files or scripts
- Reproducible runs where applicable
- Explicit documentation of assumptions
- Minimal but intentional testing or validation

**Deliverables:**
- Scripts or instructions to reproduce results
- Structured repository layout
- Clear README files focused on *why* design decisions were made

---

## Month-by-Month Breakdown

### Month 1 — Probability & Simulation
- Implement probabilistic simulations tied to coursework
- Emphasize uncertainty, variance, and interpretation

**Output:**  
✔ Simulation repo + explanatory notes

---

### Month 2 — Intelligent Systems
- Build a small agent or intelligent system
- Introduce evaluation loops and logging

**Output:**  
✔ Agent/system project with documentation

---

### Month 3 — LLM Evaluation Systems
- Build an LLM inference + evaluation pipeline
- Focus on measurement, robustness, and reproducibility

**Output:**  
✔ LLM evaluation repo + short analysis report

---

## Success Criteria (Evidence-Based)

At the end of 3 months, success means I can point to:

1. **Multiple runnable repositories** with coherent scope  
2. **Artifacts** that demonstrate system-level reasoning, not tutorials  
3. **Clear explanations** of tradeoffs and limitations  
4. **Reproducible workflows** that others could run independently  

Progress is measured by **what exists and works**, not by hours spent or content consumed.

---

## Vocational Alignment Rationale

This learning plan is designed to:
- Shift focus from passive learning to **problem ownership**
- Build **signalable career capital** for CS/AI/LLM paths
- Create artifacts usable for master’s applications, research discussions, or industry roles
- Ensure learning compounds in the **correct technical direction**

The intent is to become *harder to replace* through systems understanding and implementation, not through breadth alone.
